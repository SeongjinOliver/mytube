# 대용량 트래픽 로그인을 위한 기술



### Session 방식을 사용한 대용량 트래픽 로그인

로그인을 유지하는 방식을 위해서 Session을 사용하였습니다. Session은 클라이언트와 서버가 sessionid를 유지하고 서로 통신하는 동작 방식을 말합니다.



Session 동작 방식에 대해서 찾아보던중 Http의 통신 방식에 대해서 궁금증이 생겼습니다. 그리하여 Http의 가장 특징인 비연결성(Connectionless), 무상태(Stateless)에 대해서 찾아보았습니다.



**비연결성은(Connectionless)** 클라이언트와 서버가 한번 연결을 맺은 후, 클라이언트 요청에 대해 서버가 응답을 마치면 맺었던 연결을 끊어 버리는 성질을 말합니다.

그렇다면 비연결성의 장점과 단점을 살펴 보겠습니다.

- **비연결성의 장점**은 <u>연결을 유지하기 위한 리소스를 줄이면 더 많은 연결을 할 수 있으므로 비연결적인 특징을 갖습니다.</u>

- **비연결성의 단점**은 서버는 클라이언트를 기억하고 있지 않으므로 동일한 클라이언트의 모든 요청에 대해, 매번 새로운 연결을 시도/해제의 과정을 거쳐야하므로 <u>연결/해제에 대한 오버헤드가 발생</u>한다는 단점이 있습니다.

- 이에 대한 해결책으로 오버헤드를 줄이기 위해 HTTP의 **KeepAlive** 속성을 사용할 수 있습니다. KeepAlive는 지정된 시간동안 서버와 클라이언트 사이에서 패킷 교환이 없을 경우, 상대방의 안부를 묻기위해 패킷을 주기적으로 보내는것을 말합니다. 이 때 패킷에 반응이 없으면 접속을 끊게 됩니다.

**무상태(Stateless)**는 Connectionless로 인해 서버는 클라이언트를 식별할 수 없는데 이것을 Stateless라고합니다. http와 같이 client의 이전 상태를 기록하지 않는 접속이란 의미입니다. 그에 비해 **상태(Stateful)**은 client의 이전 상태를 기록하고 있는 것입니다. 



Stateless는 웹서버가 사용자의 작업을 기억하고 있지 않다는 의미이고 Stateful은 사용자의 상태를 서버가 기억하고 있다가 유용한 정보로써 활용한다는 것입니다. 이를 바탕으로 Session은 Stateless합니다.



이렇게 로그인을 구현하였지만 많은 사용자들의 요청으로 대용량 트래픽이 요구되면 문제가 생길 수 있다고 생각했습니다. 이로 인해 해결점이 필요하고 어떠한 방식으로 해결해야할지 궁금증이 생겼습니다.



여러가지 자료를 보고 공부를 한 후 알게 된점은 대용량 서비스를 운영하려면 부하 분산을 해야합니다. 대용량 트래픽을 장애 없이 처리하려면 여러 대의 서버에 적절히 트래픽을 분배해야 합니다. 그래서 부하 분산이란 무엇인가를 알아보겠습니다.



**부하분산**은 위키백과에 따르면

> **부하분산** 또는 **로드 밸런싱**(load balancing)[[1\]](https://ko.wikipedia.org/wiki/부하분산#cite_note-:1-1)은 컴퓨터 네트워크 기술의 일종으로 둘 혹은 셋이상의 [중앙처리장치](https://ko.wikipedia.org/wiki/중앙처리장치) 혹은 [저장장치](https://ko.wikipedia.org/wiki/저장장치)와 같은 컴퓨터 자원들에게 작업을 나누는 것을 의미한다.



많은 블로그와 문서 중에는 **load balancing, sticky session, session clustering, scale up, scale out**이라는 단어들에 대해서 설명하고 있었습니다. 이 단어들을 통해서 Session 방식의 대용량 트래픽을 다루는 방법에 대해서 설명 하고 있었습니다.



---



대용량 서비스를 운영하려면 부하 분산은 필수입니다. 대용량 트래픽을 장애 없이 처리하려면 여러 대의 서버에 적절히 트래픽을 분배해야 합니다.

### 로드 밸런싱

로드 밸런싱이란 부하 분산을 위해서 클라이언트로 오는 모든 요청을 VIP(Virtua IP)를 통해 여러 서버로 분산 해주는 기능을 말합니다. 로드밸런싱을 해주는 소프트웨어 또는 하드웨어 장비를 로드밸런서라고 합니다.



![image](https://user-images.githubusercontent.com/55625864/93168515-04ef4e80-f75e-11ea-94fe-b6e2afb51034.png)



로드 밸런싱의 주요 기술은 NAT(Network Address Translation) , DSR(Dynamic Source Routing protocol), Tunneling이 있다. 

> **NAT**는 private IP를 public IP로 바꾸는데 사용하는 통신망의 주소변조기

> **DSR**은 로드밸런서 사용시 서버에서 클라이언트로 되돌아가는 경우 목적지 주소를 클라이언트의 IP주소로 전달해서 네트워크 스위치를 거치지 않고 바로 클라이언트를 찾음

> **Tunneling**은 인터넷 상에서 눈에 보이지 않는 통로를 만들어 통신할 수 있게 하는 개념으로, 데이터를 캡슐화해서 연결된 상호 간에만 캡슐화된 패킷을 구별해 캡슐화를 해제함.



그렇다면 로드 밸런싱을 이용하여 통신 하는 것을 예로 들어서 생각해 볼 필요가 있습니다. 여러대의 서버가 있을 때 클라이언트가 첫 요청을 A서버에 보내 통신을 합니다. 그런데 로드 밸런서를 통해 이번에는 B서버에 전달이 된다면 B서버에는 sessionid가 없으므로 응답에 실패할 수 있습니다. 따라서, 다른 서버에 접속하면 session이 공유되지 않게 됩니다. 이러한 세션 관리를 해결하기 위한 것중 하나는 바로 sticky session입니다.

### sticky session

**sticky session**은 첫 요청한 서버에 sessionid를 저장하고 이 서버와만 통신 하는 것을 말합니다. 모든 요청을 첫요청한 특정 서버로 고정하는 방법으로 session을 관리 합니다.



sticky session을 사용하면 정합성 이슈를 해결할 수 없고 스케일 아웃의 장점인 가용성과 트래픽 분산을 완벽히 사용할 수 없습니다. 이것은 고정 session 서버의 균형을 유지하기 어렵게 만듭니다. 많은 세션이 누적되거나 특정 고정 session에 많은 리소스가 필요한 경우 서버 과부하가 올 수 있습니다. 이로써, 로드 밸런서가 세션 중간에 클라이언트를 다른 서버로 이동하여 데이터가 손실 될 수 있습니다. 따라서, 서버 한대에 장애가 발생하면 도중에 다른 서버로 접속을 하게 되기 때문에 세션 정보가 없어 문제가 발생할 수 있습니다.



이러한 단점을 고려한 session 관리 기법 중 session clustering 방식이 있습니다.



### session clustering

**클러스터링**은 여러 개념에서 의미를 다르게 두지만 여기서 설명할 클러스터링이란 것은 여러대의 서버가 동시에 한가지 업무를 수행하도록 만드는 것입니다. 이를테면 DB가 한대 있는데 이 한대가 뻗으면 시스템 장애가 납니다. (SPOF - Single Point Of Failure). 만약 2대를 클러스터링 해 놓고 각각의 역할을 수행하다가 한대가 뻗으면 나머지 한대가 역할을 대신 수행하도록 하여 위의 문제를 해결하면서 지속적인 서비스를 제공할 수 있습니다. 또한 클러스터링의 장점은 부하 분산, 성능 향상, 가용성 향상, Failover(시스템 대체 작동)입니다.



**session clustering**은 동일한 session을 여러 WAS에서 사용할 수 있게 관리 하는 것을 의미합니다. 만약 WAS가 2대 이상 설치 되있을 경우 동일한 세션을 여러 WAS에서 관리할 수 있습니다. 이러한 점은 하나의 서버의 장애가 일어 났을 때 다른 서버로 대체해서 장애를 방지 할 수 있습니다. 하나의 WAS가 장애가 발생하면 해당 WAS가 들고 있던 세션은 다른 WAS로 이동되어 해당 세션을 관리하게 됩니다.



모든 서버가 동일한 세션 객체를 가져야 하기 때문에 많은 메모리가 필요합니다. 또한 세션 저장소에 데이터가 저장될 때마다 모든 서버에 값을 입력해야 하므로 서버 수에 비례하여 네트워크 트래픽이 증가하는 등 성능 저하가 발생하게 됩니다. 그러므로 해당 방식은 소규모 클러스터에서 좋은 효율을 보여줍니다. 4대 이상의 서버를 가진 대규모 클러스터에는 추천하지 않는 방식입니다.



Tomact에서는 Cluster Session Manager 종류를 2가지로 구분하고 소규모 클러스터와 대규모 클러스터를 구분해서 사용합니다. 소규모 클러스터는 “*DeltaManager*”를 사용하고, 대규모 클러스터는 “*BackupManager*”를 사용합니다. *DeltaManager*를 사용하여 세션 상태의 all-to-all session replication를 수행하거나 *BackupManager*를 사용하여 하나의 노드에만 백업 복제를 수행 할 수 있습니다.



위에서 설명한 session clustering 방식은 *DeltaManager*의 all-to-all session replication 방식입니다. 이것은 새로운 session 요청이나 변경되는 요소의 session 요청이 발생했을 때, 해당 sessionid를 다른 모든 session 저장소에 복제 되는 것을 의미합니다. 이로써 어떤 서버에 접속해도 sessionid을 유지하여 정합성 이슈가 해결 가능하고, 한 서버가 장애를 일으켜도 서비스는 중단되지 않고 운영할 수 있습니다. 위에서도 언급했지만 이 방식은 4대 이상의 서버를 가진 대규모 클러스터에는 권장하지 않는 방식입니다.



대규모 클러스터를 사용하면 정보가 변경될때마다 세션 객체를 복제하기 때문에 서버 대수가 많을 수록 네트워크 트래픽이 높아지고 메모리 소모가 심해집니다. 



*BackupManager*는 하나의 서버에만 복제하기 때문에 *DeltaManager*의 all-to-all 단점을 커버할 수 있으며 failover(시스템 대체 작동)도 지원합니다. Primary 서버와 Backup(Secondary) 서버로 분리되어 모든 노드에 복제하지 않고 Backup 서버에만 복제합니다.



이러한 방식을 사용할 경우 한 세션 저장소에 오류가 발생하더라도 복구가 가능하므로 서버에 복제시키는데 발생하는 비용이 증가하기 때문에 Scale-Out이 많이 진행될수록 비효율적이 됩니다.



---



### 인메모리 와 디스크 기반 데이터베이스

위와 같은 방법을 해결하기 위해서 **독립된 세션 스토리지**를 사용합니다. 각 서버와 연결된 독립된 세션 저장소를 구성하는 것입니다. 여러 대의 서버가 하나의 세션 저장소를 공유하기 때문에 데이터의 동기화를 위한 비용이 발생하지 않습니다. 일반적으로 Redis와 같은 In-memory 저장소를 활용하며, 일반적인 관계형 데이터베이스 저장소도 사용할 수 있습니다.



**그렇다면 어떤 종류의 데이터베이스로 세션 스토리지를 사용할 수 있는지 생각해봐야합니다.**

우리가 자주 사용하는 SNS가 하루에 생성해내는 데이터가 얼마나 많을지 생각해 본적 있나요? 

![image](https://user-images.githubusercontent.com/55625864/93552796-6f95c980-f9ac-11ea-9ddf-583448c382b0.png)

위 자료만 봐도 정말 상상을 할 수 없을 정도의 사용자들에 의해서 많은 데이터 생성 증가량이 폭주하고 있습니다. 우리가 개발해야할 서비스들이 이처럼 엄청난 데이터를 사용해야하며 빠른 처리속도에 대한 고민을 안할 수 가 없을 것같습니다. 그래서 선배님들은 많은 양의 데이터를 빠르게 처리하기 위해 전통적인 하드디스크 기반의 DBMS가 아닌 메모리 기반의 DBMS를 사용하기 시작했습니다. 그렇다면 왜 하드디스크 기반의 데이터베이스에서 메모리 기반의 데이터베이스를 선택해서 개발하는지 알아보겠습니다.



인메모리 데이터베이스 wiki에 따르면

> 인메모리 데이터베이스는 디스크에 최적화된 데이터베이스보다 더 빠른데 그 까닭은 **디스크 접근이 메모리 접근보다 느리기 때문**이며, 이 데이터베이스는 내부 최적화 알고리즘이 더 단순하며 더 적은 CPU 명령을 실행한다. 메모리의 데이터에 접근하면 데이터를 조회할 때 검색 시간이 줄어들며 디스크보다 더 빠르고 더 예측 가능성 성능을 제공한다.

위로 인해 디스크 데이터베이스보다 느리다는 이유를 알수있습니다. 그렇다면 조금 더 자세히 알아보겠습니다.



인메모리 데이터베이스와 디스크기반, 즉 전통적인 데이터베이스의 차이점과 데이터를 저장하는 장소인 RAM / SSD / HDD 의 특징과 차이점을 알아보면 왜 디스크 접근이 메모리 접근보다 느리다는 이유를 설명할 수 있을 것 같습니다.

![image](https://user-images.githubusercontent.com/55625864/93555704-b89c4c80-f9b1-11ea-8f40-d1a497ead659.png)



**RAM (Random Access Memory)**

임의의 영역에 접근하고 읽고 쓰기가 가능한 주기억 장치. 램은 어느 위치에 저장된 데이터든지 접근(읽기 및 쓰기)하는 데 동일한 시간이 걸리는 메모리이기에 '랜덤'이라는 명칭이 주어졌습니다. 하드 디스크는 저장된 위치에 따라 접근하는 데 걸리는 시간이 다릅니다. 랜덤 액세스 시간은 약 수십 나노초입니다. RAM은 초당 100MB로 랜덤 읽기/쓰기를 수행합니다. 순차적으로 읽기/쓰기는 초당 1GB 이상으로 훨씬 더 빠릅니다. [Random-access memory에서](https://en.wikipedia.org/wiki/Random-access_memory) RAM 작동 방식에 대한 자세한 정보를 찾을 수 있습니다 .



**SSD**

랜덤 액세스 시간은 약 0.1밀리초입니다. SSD는 RAM보다 느립니다. 랜덤 액세스 시간은 초당 약 10,000 개의 블록을 무작위로 읽을 수 있습니다. 각 블록에서 1 바이트 만 필요한 최악의 시나리오에서 속도는 초당 10kB입니다. **RAM보다 1,000 배 느립니다**. 그러나 순차 읽기/쓰기는 초당 약 200-300MB로 수행되며 이는 RAM과 다소 비슷합니다. SSD에 대한 자세한 내용은 [Solid-state drive](https://en.wikipedia.org/wiki/Solid-state_drive) 와 [Hard disk drive performance characteristics ](https://en.wikipedia.org/wiki/Hard_disk_drive_performance_characteristics)에 있습니다.



**HDD**

문제의 세 가지 스토리지 유형 중 가장 느린 유형입니다. 랜덤 액세스 시간은 약 10 밀리 초로 SSD보다 100 배 더 느립니다. 초당 100 개 블록을 임의로 읽고 쓸 수 있습니다. 즉, 랜덤 바이트를 읽어야하는 경우 속도는 100 바이트입니다. 자세한 내용은 [Hard disk drive](https://en.wikipedia.org/wiki/Hard_disk_drive) 와 [Hard disk drive performance characteristics](https://en.wikipedia.org/wiki/Hard_disk_drive_performance_characteristics) 에서 확인할 수 있습니다 .



RAM, SSD, HDD이 3가지를 비교했을 때 순서대로 RAM  > SSD > HDD의 속도를 확인할 수 있습니다.  이제 메모리 접근 속도가 훨씬 빠르다는것을 알게되었습니다. 따라서 인메모리 데이터베이스는 데이터 양의 증가로 데이터베이스 응답 속도가 떨어지는 문제를 해결할 대안이 될 수 있습니다. 인메모리 데이터베이스는 내부 최적화 알고리즘이 단순하여 더 적은 CPU 명령을 실행하며, 예측 가능한 성능이 높습니다.



지금까지 디스크 기반 메모리와 비교하여 인메모리 데이터베이스의 장점을 알아보았습니다. 따라서 세션 저장소는 인메모리 데이터 저장소를 사용해야 한다는 것을 알게되었습니다.



그렇다면 인메모리 데이터 저장소는 무엇이 있고 어떤 기능들을 하는지 알아보겠습니다. 



### [Cache] Redis vs Memcached

Redis(Remote Dictionary Storage, 레디스)와 Memcached(맴캐시드)는 유명한 오픈소스인, 인메모리 데이터 저장소입니다.



**—>>> 작성중**



---



위에서 무심코 언급해던 Scale-out에 대해서 조금더 알아 보고 이것과 다르지만 서버의 용량을 늘리기위한 방법중 하나인 Scale-up도 같이 살펴보겠습니다.



### Scale-up, Scale-out

서비스 성능 향상을 위해서 scale-up, scale-out 방식을 사용합니다. **scale-up**은 서버 자체를 증강(CPU 변경, RAM 추가 등 하드웨어 장비의 성능을 높임)하는 것에 의해서 처리 능력을 향상시키는 것이고, **scale-out**은 접속된 서버의 대수를 늘려서 처리 능력을 향상 시키는 것입니다.



scale-up은 수직 확장이며 성능 확장에 한계가 있고, 한대의 서버에 부하가 집중되어 장애 가능성이 높습니다. scale-out은 수평 확장이며 지속적 확장이 가능하고, 읽기/쓰기가 여러 대의 서버에 분산 처리 장애 시 전면 장애의 가능성이 적습니다. 비용측면에서는 scale-up이 성능 증가에 따른 비용 증가폭이 크고, scale-out은 비교적 저렴한 서버 사용으로 비용 부담이 적습니다.

![image](https://user-images.githubusercontent.com/55625864/93166888-5eee1500-f75a-11ea-9483-d15aa3e148fd.png)



![image](https://user-images.githubusercontent.com/55625864/93166818-3c5bfc00-f75a-11ea-837b-239f66dfe7ed.png)



**그렇다면 scale-up과 scale-out은 언제 사용될까요?**

웹사이트의 접속자가 증가해서 트래픽이 많이 발생할 경우에는 scale-out이 scale-up 보다는 효과적입니다. 그 반면, 데이터베이스의 빈번한 갱신이 필요한 OLTP(온라인 트랜잭션)에서는 scale-out보다는 scale-up이 효과적입니다. legacy인 scale-up을 지양하는것이 아니라 두개의 장단점을 알고 사용하는 것이 중요합니다.



하지만 이 방식은 scale out에서 새로운 서버가 하나 생성될 때마다 기존에 존재하던 WAS에 새로운 서버의 IP/Port를 입력해서 클러스터링하는 단점이 있습니다.



**<u>*scale out과 session clustering을 함께 사용할 때의 단점을 더 찾아보고 추가해야함!!*</u>**

**<u>*아직 미완성*</u>**



#### 참고

- [Session (computer science) wiki](https://en.wikipedia.org/wiki/Session_(computer_science))
- [부하분산 wiki](https://ko.wikipedia.org/wiki/%EB%B6%80%ED%95%98%EB%B6%84%EC%82%B0)
- 🙈[[HTTP\] HTTP 특성(비연결성, 무상태)과 구성요소 그리고 Restful API🐵](https://victorydntmd.tistory.com/286)
- [패킷과 패킷 트래픽 송수신 전송 흐름](https://blog.naver.com/sung_mk1919/221177021021)
- [[웹 개념] HTTP 통신의 과정](https://cordelia273.space/11)
- [Load Balancers, An Analogy](https://codeburst.io/load-balancers-an-analogy-cc64d9430db0)
- [Sticky Session과 Session Clustering](https://smjeon.dev/web/sticky-session/)
- [Sticky Session](https://www.imperva.com/learn/availability/sticky-session-persistence-and-cookies/)
- [세션 클러스터링](https://brownbears.tistory.com/168)
- [클러스터링 / 세션 복제 방법](http://tomcat.apache.org/tomcat-9.0-doc/cluster-howto.html)
- [톰캣 운영 노하우](https://www.slideshare.net/jieunsys/ss-56543446)
- [인메모리 데이터베이스](https://ko.wikipedia.org/wiki/%EC%9D%B8%EB%A9%94%EB%AA%A8%EB%A6%AC_%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A4)
- [When and why I use an in-memory database or a traditional database management system](https://medium.com/@denisanikin/when-and-why-i-use-an-in-memory-database-or-a-traditional-database-management-system-5737f6d406b5)

- [[Cache] Redis vs. Memcached](https://medium.com/@chrisjune_13837/redis-vs-memcached-10e796ddd717)