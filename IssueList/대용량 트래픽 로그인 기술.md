# 대용량 트래픽 로그인을 위한 기술



### Session 방식을 사용한 대용량 트래픽 로그인

로그인을 유지하는 방식을 위해서 Session을 사용하였습니다. Session은 클라이언트와 서버가 sessionid를 유지하고 서로 통신하는 동작 방식을 말합니다.



Session 동작 방식에 대해서 찾아보던중 Http의 통신 방식에 대해서 궁금증이 생겼습니다. 그리하여 Http의 가장 특징인 비연결성(Connectionless), 무상태(Stateless)에 대해서 찾아보았습니다.



**비연결성은(Connectionless)** 클라이언트와 서버가 한번 연결을 맺은 후, 클라이언트 요청에 대해 서버가 응답을 마치면 맺었던 연결을 끊어 버리는 성질을 말합니다.

그렇다면 비연결성의 장점과 단점을 살펴 보겠습니다.

- **비연결성의 장점**은 <u>연결을 유지하기 위한 리소스를 줄이면 더 많은 연결을 할 수 있으므로 비연결적인 특징을 갖습니다.</u>

- **비연결성의 단점**은 서버는 클라이언트를 기억하고 있지 않으므로 동일한 클라이언트의 모든 요청에 대해, 매번 새로운 연결을 시도/해제의 과정을 거쳐야하므로 <u>연결/해제에 대한 오버헤드가 발생</u>한다는 단점이 있습니다.

- 이에 대한 해결책으로 오버헤드를 줄이기 위해 HTTP의 **KeepAlive** 속성을 사용할 수 있습니다. KeepAlive는 지정된 시간동안 서버와 클라이언트 사이에서 패킷 교환이 없을 경우, 상대방의 안부를 묻기위해 패킷을 주기적으로 보내는것을 말합니다. 이 때 패킷에 반응이 없으면 접속을 끊게 됩니다.

**무상태(Stateless)**는 Connectionless로 인해 서버는 클라이언트를 식별할 수 없는데 이것을 Stateless라고합니다. http와 같이 client의 이전 상태를 기록하지 않는 접속이란 의미입니다. 그에 비해 **상태(Stateful)**은 client의 이전 상태를 기록하고 있는 것입니다. 



Stateless는 웹서버가 사용자의 작업을 기억하고 있지 않다는 의미이고 Stateful은 사용자의 상태를 서버가 기억하고 있다가 유용한 정보로써 활용한다는 것입니다. 이를 바탕으로 Session은 Stateless합니다.



이렇게 로그인을 구현하였지만 많은 사용자들의 요청으로 대용량 트래픽이 요구되면 문제가 생길 수 있다고 생각했습니다. 이로 인해 해결점이 필요하고 어떠한 방식으로 해결해야할지 궁금증이 생겼습니다.



여러가지 자료를 보고 공부를 한 후 알게 된점은 대용량 서비스를 운영하려면 부하 분산을 해야합니다. 대용량 트래픽을 장애 없이 처리하려면 여러 대의 서버에 적절히 트래픽을 분배해야 합니다. 그래서 부하 분산이란 무엇인가를 알아보겠습니다.



**부하분산**은 위키백과에 따르면

> **부하분산** 또는 **로드 밸런싱**(load balancing)[[1\]](https://ko.wikipedia.org/wiki/부하분산#cite_note-:1-1)은 컴퓨터 네트워크 기술의 일종으로 둘 혹은 셋이상의 [중앙처리장치](https://ko.wikipedia.org/wiki/중앙처리장치) 혹은 [저장장치](https://ko.wikipedia.org/wiki/저장장치)와 같은 컴퓨터 자원들에게 작업을 나누는 것을 의미한다.



많은 블로그와 문서 중에는 **load balancing, sticky session, session clustering, scale up, scale out**이라는 단어들에 대해서 설명하고 있었습니다. 이 단어들을 통해서 Session 방식의 대용량 트래픽을 다루는 방법에 대해서 설명 하고 있었습니다.



---



대용량 서비스를 운영하려면 부하 분산은 필수입니다. 대용량 트래픽을 장애 없이 처리하려면 여러 대의 서버에 적절히 트래픽을 분배해야 합니다.

### 로드 밸런싱

로드 밸런싱이란 부하 분산을 위해서 클라이언트로 오는 모든 요청을 VIP(Virtua IP)를 통해 여러 서버로 분산 해주는 기능을 말합니다. 로드밸런싱을 해주는 소프트웨어 또는 하드웨어 장비를 로드밸런서라고 합니다.



![image](https://user-images.githubusercontent.com/55625864/93168515-04ef4e80-f75e-11ea-94fe-b6e2afb51034.png)



로드 밸런싱의 주요 기술은 NAT(Network Address Translation) , DSR(Dynamic Source Routing protocol), Tunneling이 있다. 

> **NAT**는 private IP를 public IP로 바꾸는데 사용하는 통신망의 주소변조기

> **DSR**은 로드밸런서 사용시 서버에서 클라이언트로 되돌아가는 경우 목적지 주소를 클라이언트의 IP주소로 전달해서 네트워크 스위치를 거치지 않고 바로 클라이언트를 찾음

> **Tunneling**은 인터넷 상에서 눈에 보이지 않는 통로를 만들어 통신할 수 있게 하는 개념으로, 데이터를 캡슐화해서 연결된 상호 간에만 캡슐화된 패킷을 구별해 캡슐화를 해제함.



그렇다면 로드 밸런싱을 이용하여 통신 하는 것을 예로 들어서 생각해 볼 필요가 있습니다. 여러대의 서버가 있을 때 클라이언트가 첫 요청을 A서버에 보내 통신을 합니다. 그런데 로드 밸런서를 통해 이번에는 B서버에 전달이 된다면 B서버에는 sessionid가 없으므로 응답에 실패할 수 있습니다. 따라서, 다른 서버에 접속하면 session이 공유되지 않게 됩니다. 이러한 세션 관리를 해결하기 위한 것중 하나는 바로 sticky session입니다.

### sticky session

**sticky session**은 첫 요청한 서버에 sessionid를 저장하고 이 서버와만 통신 하는 것을 말합니다. 모든 요청을 첫요청한 특정 서버로 고정하는 방법으로 session을 관리 합니다.



하지만, 고정 session은 서버의 균형을 유지하기 어렵게 만듭니다. 많은 세션이 누적되거나 특정 고정 session에 많은 리소스가 필요한 경우 서버가 과부하가 올 수 있습니다. 이로써, 로드 밸런서가 세션 중간에 클라이언트를 다른 서버로 이동하여 데이터가 손실 될 수 있습니다. 따라서, 서버 한대에 장애가 발생하면 도중에 다른 서버로 접속을 하게 되기 때문에 세션 정보가 없어 문제가 발생할 수 있습니다.



이러한 단점을 고려한 session 관리 기법 중 session clustering 방식이 있습니다.



### session clustering

**클러스터링**은 여러 개념에서 의미를 다르게 두지만 여기서 설명할 클러스터링이란 것은 여러대의 서버가 동시에 한가지 업무를 수행하도록 만드는 것입니다. 이를테면 DB가 한대 있는데 이 한대가 뻗으면 시스템 장애가 납니다 (SPOF - Single Point Of Failure). 만약 2대를 클러스터링 해 놓고 각각의 역할을 수행하다가 한놈이 뻗으면 나머지 한놈이 그 역할을 대신 수행하도록 하면 위와 같은 문제를 해결하면서 지속적인 서비스를 제공해줄 수 있게 됩니다.



**session clustering**은 동일한 session을 여러 WAS에서 사용할 수 있게 관리 하는 것을 의미합니다. 만약 WAS가 2대 이상 설치 되있을 경우 동일한 세션을 여러 WAS에서 관리할 수 있습니다. 이러한 점은 하나의 서버의 장애가 일어 났을 때 다른 서버로 대체해서 장애를 방지 할 수 있습니다. 하나의 WAS가 장애가 발생하면 해당 WAS가 들고 있던 세션은 다른 WAS로 이동되어 해당 세션을 관리하게 됩니다.



이러한 방식으로 서버는 여유롭게 사용자가 원하는 결과를 응답 할수 있습니다. 하지만 Client가 한 두명이 아닌 수백, 수천명이라면 이것을 해결해야할 방안이 필요합니다.



### Scale-up, Scale-out

문제를 해결하기 위해서는 scale-up, scale-out 방식을 사용합니다. **scale-up**은 서버 자체를 증강(CPU 변경, RAM 추가 등 하드웨어 장비의 성능을 높임)하는 것에 의해서 처리 능력을 향상시키는 것이고, **scale-out**은 접속된 서버의 대수를 늘려서 처리 능력을 향상 시키는 것입니다.



scale-up은 수직 확장이며 성능 확장에 한계가 있고, 한대의 서버에 부하가 집중되어 장애 가능성이 높습니다. scale-out은 수평 확장이며 지속적 확장이 가능하고, 읽기/쓰기가 여러 대의 서버에 분산 처리 장애 시 전면 장애의 가능성이 적습니다. 비용측면에서는 scale-up이 성능 증가에 따른 비용 증가폭이 크고, scale-out은 비교적 저렴한 서버 사용으로 비용 부담이 적습니다.

![image](https://user-images.githubusercontent.com/55625864/93166888-5eee1500-f75a-11ea-9483-d15aa3e148fd.png)



![image](https://user-images.githubusercontent.com/55625864/93166818-3c5bfc00-f75a-11ea-837b-239f66dfe7ed.png)



**그렇다면 scale-up과 scale-out은 언제 사용될까요?**

웹사이트의 접속자가 증가해서 트래픽이 많이 발생할 경우에는 scale-out이 scale-up 보다는 효과적입니다. 그 반면, 데이터베이스의 빈번한 갱신이 필요한 OLTP(온라인 트랜잭션)에서는 scale-out보다는 scale-up이 효과적입니다. legacy인 scale-up을 지양하는것이 아니라 두개의 장단점을 알고 사용하는 것이 중요합니다.



하지만 이 방식은 scale out에서 새로운 서버가 하나 생성될 때마다 기존에 존재하던 WAS에 새로운 서버의 IP/Port를 입력해서 클러스터링하는 단점이 있습니다.



**<u>*scale out과 session clustering을 함께 사용할 때의 단점을 더 찾아보고 추가해야함!!*</u>**

**<u>*아직 미완성*</u>**



#### 참고

- [Session (computer science) wiki](https://en.wikipedia.org/wiki/Session_(computer_science))
- [부하분산 wiki](https://ko.wikipedia.org/wiki/%EB%B6%80%ED%95%98%EB%B6%84%EC%82%B0)
- 🙈[[HTTP\] HTTP 특성(비연결성, 무상태)과 구성요소 그리고 Restful API🐵](https://victorydntmd.tistory.com/286)
- [패킷과 패킷 트래픽 송수신 전송 흐름](https://blog.naver.com/sung_mk1919/221177021021)
- [[웹 개념] HTTP 통신의 과정](https://cordelia273.space/11)
- [Load Balancers, An Analogy](https://codeburst.io/load-balancers-an-analogy-cc64d9430db0)
- [Sticky Session과 Session Clustering](https://smjeon.dev/web/sticky-session/)
- [Sticky Session](https://www.imperva.com/learn/availability/sticky-session-persistence-and-cookies/)
- [세션 클러스터링](https://brownbears.tistory.com/168)